{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e9c475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import json\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "SCHEMA_NAME = \"soda_checks\"\n",
    "TABLE_NAME = \"data_quality_checks\"\n",
    "\n",
    "\n",
    "class DataQualityCheckLoader:\n",
    "    def __init__(self, host, db_name, username, password, schema, table):\n",
    "        self.host = host\n",
    "        self.db_name = db_name\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.schema = schema\n",
    "        self.table = table\n",
    "        self.conn = self.create_pg_connection()\n",
    "\n",
    "    def create_pg_connection(self):\n",
    "        host_split = self.host.split(':')\n",
    "        return psycopg2.connect(\n",
    "            host=host_split[0],\n",
    "            port=host_split[1] if len(host_split) > 1 else 5432,\n",
    "            dbname=self.db_name,\n",
    "            user=self.username,\n",
    "            password=self.password\n",
    "        )\n",
    "\n",
    "    def ensure_schema_and_table(self):\n",
    "        with self.conn.cursor() as cur:\n",
    "            cur.execute(f\"CREATE SCHEMA IF NOT EXISTS {self.schema};\")\n",
    "            cur.execute(f\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS {self.schema}.{self.table} (\n",
    "                    id TEXT PRIMARY KEY,\n",
    "                    data_source TEXT,\n",
    "                    table_name TEXT,\n",
    "                    check_name TEXT,\n",
    "                    column_name TEXT,\n",
    "                    metric_id TEXT[],\n",
    "                    outcome TEXT,\n",
    "                    value DOUBLE PRECISION,\n",
    "                    timestamp TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n",
    "                );\n",
    "            \"\"\")\n",
    "        self.conn.commit()\n",
    "\n",
    "    @staticmethod\n",
    "    def load_json_to_records(json_path):\n",
    "        with open(json_path, \"r\") as f:\n",
    "            soda_json = json.load(f)\n",
    "        records = []\n",
    "        timestamp = soda_json.get(\"dataTimestamp\")\n",
    "        for check in soda_json.get(\"checks\", []):\n",
    "            records.append({\n",
    "                \"id\": check.get(\"identity\"),\n",
    "                \"data_source\": check.get(\"dataSource\"),\n",
    "                \"table_name\": check.get(\"table\"),\n",
    "                \"check_name\": check.get(\"name\"),\n",
    "                \"column_name\": check.get(\"column\"),\n",
    "                \"metric_id\": check.get(\"metrics\"),\n",
    "                \"outcome\": check.get(\"outcome\"),\n",
    "                \"value\": check.get(\"diagnostics\", {}).get(\"value\"),\n",
    "                \"timestamp\": timestamp\n",
    "            })\n",
    "        return records\n",
    "\n",
    "    def insert_records(self, records):\n",
    "        if not records:\n",
    "            print(\"No records to insert.\")\n",
    "            return\n",
    "        columns = [\"id\", \"data_source\", \"table_name\", \"check_name\", \"column_name\", \"metric_id\", \"outcome\", \"value\", \"timestamp\"]\n",
    "        values = [\n",
    "            (\n",
    "                rec[\"id\"],\n",
    "                rec[\"data_source\"],\n",
    "                rec[\"table_name\"],\n",
    "                rec[\"check_name\"],\n",
    "                rec[\"column_name\"],\n",
    "                rec[\"metric_id\"],\n",
    "                rec[\"outcome\"],\n",
    "                rec[\"value\"],\n",
    "                rec[\"timestamp\"]\n",
    "            )\n",
    "            for rec in records\n",
    "        ]\n",
    "        insert_sql = f\"\"\"\n",
    "            INSERT INTO {self.schema}.{self.table} ({', '.join(columns)})\n",
    "            VALUES %s\n",
    "            ON CONFLICT (id) DO NOTHING;\n",
    "        \"\"\"\n",
    "        with self.conn.cursor() as cur:\n",
    "            execute_values(cur, insert_sql, values)\n",
    "        self.conn.commit()\n",
    "        print(f\"Inserted {len(values)} records into {self.schema}.{self.table}.\")\n",
    "\n",
    "    def close(self):\n",
    "        if self.conn:\n",
    "            self.conn.close()\n",
    "\n",
    "\n",
    "dq_loader = DataQualityCheckLoader(\n",
    "    host='localhost:5432',\n",
    "    db_name='mydb',\n",
    "    username='myuser',\n",
    "    password='mypassword',\n",
    "    schema=SCHEMA_NAME,\n",
    "    table=TABLE_NAME\n",
    ")\n",
    "\n",
    "dq_loader.ensure_schema_and_table()\n",
    "records = dq_loader.load_json_to_records(\"wordline_velocity_dq_results.json\")\n",
    "dq_loader.insert_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9fc0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Helper to generate fake data\n",
    "def generate_fake_data(n=30):\n",
    "    base_timestamp = datetime(2025, 6, 1, 9, 0)\n",
    "\n",
    "    data = []\n",
    "    for i in range(n):\n",
    "        row = {\n",
    "            \"id\": str(uuid.uuid4())[:8],\n",
    "            \"data_source\": random.choice(['ods', 'dsa', 'dtm']),\n",
    "            \"table_name\": random.choice(['table1', 'table2', 'table3', 'table4', 'table5']),\n",
    "            \"check_name\": random.choice([\n",
    "                \"row_count > 0\",\n",
    "                \"Schema Check\",\n",
    "                \"check_last_payment_date\",\n",
    "                \"missing_count(\\\"productId\\\") = 0\"\n",
    "            ]),\n",
    "            \"column_name\": random.choice([None, \"productId\", \"lastPaymentDate\", \"amount\", \"status\", \"customerId\"]),\n",
    "            \"metric_id\": f\"metric-{uuid.uuid4()}\",\n",
    "            \"outcome\": random.choice(['pass', 'fail', 'warn']),\n",
    "            \"value\": round(random.uniform(0.0, 20.0), 2),\n",
    "            \"timestamp\": base_timestamp + timedelta(hours=random.randint(0, 96))\n",
    "        }\n",
    "        data.append(row)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df_fake = generate_fake_data(100)\n",
    "\n",
    "fake_records = []\n",
    "for _, check in df_fake.iterrows():\n",
    "    fake_records.append({\n",
    "        \"id\": check[\"id\"],\n",
    "        \"data_source\": check[\"data_source\"],\n",
    "        \"table_name\": check[\"table_name\"],\n",
    "        \"check_name\": check[\"check_name\"],\n",
    "        \"column_name\": check[\"column_name\"],\n",
    "        \"metric_id\": [check[\"metric_id\"]],\n",
    "        \"outcome\": check[\"outcome\"],\n",
    "        \"value\": check[\"value\"],\n",
    "        \"timestamp\": check[\"timestamp\"]\n",
    "    })\n",
    "\n",
    "fake_records\n",
    "\n",
    "dq_loader.insert_records(fake_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a5f7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port=5432,\n",
    "    dbname=\"mydb\",\n",
    "    user=\"myuser\",\n",
    "    password=\"mypassword\"\n",
    ")\n",
    "\n",
    "# Define your connection string (PostgreSQL)\n",
    "conn_str = \"postgresql://myuser:mypassword@localhost:5432/mydb\"\n",
    "\n",
    "# Define your SQL query\n",
    "query = \"SELECT * FROM soda_checks.data_quality_checks\"\n",
    "\n",
    "# Read the table using Polars and ConnectorX\n",
    "df = pl.read_database(query, connection=conn)\n",
    "\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
